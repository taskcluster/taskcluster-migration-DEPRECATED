stop-bbb:
    title: "Turn off and decommission the Buildbot Bridge"
    dependencies:
        - stop-bb-build-masters
        - stop-bb-test-masters

stop-bb-schedulers:
    # NOTE: by this time, the schedulers should not be creating any build requests (everything
    # should already be disabled)
    title: "Shut off BB Schedulers (except one for ESR et al.)"
    dependencies:
        - fuzzing
        - seta-in-tree
        - periodic-update-service
        - windows-opt-tier1
        - linux32-opt-tier1
        - linux64-opt-tier1
        - macosx-all-tier1
        - stop-bb-build-masters

stop-bb-test-masters:
    title: "Turn off the Test Buildmasters (except one of each for ESR et al.)"
    dependencies:
        - stop-bb-macosx-test-masters
        - stop-bb-linux-test-masters
        - stop-bb-windows-test-masters

stop-bb-build-masters:
    title: "Turn off the Build Buildmasters (except one of each for ESR et al.)"
    dependencies:
        - stop-releasetasks-via-bbb
        - macosx-disable-bb-builds
        - linux32-disable-bb-builds
        - linux64-disable-bb-builds
        - windows-disable-bb-builds
        - android-disable-bb-builds

seta-in-tree:
    title: "SETA support in tree"
    description: in-tree taskgraph generation correctly skips low-value tests
    bug: 1287018
    done: true
    assigned: MikeLing

in-tree-bbb-support:
    title: "Support for invoking BB jobs from decision tasks via BBB"
    bug: 1316077
    description: |
        This involves building in-tree infrastructure to create the proper
        payload for BBB to run test tasks against builds made in TaskCluster.
        Likely the hardest part is generating the BuilderName correctly.
    assigned: wcosta
    done: true

beetmover-worker-impl:
    # "beetworker"?
    title: "Implement and deploy a Beetmoover Worker based on scriptworker"
    bug: 1282188
    done: true
    assigned: mtabara

balrog-worker-impl:
    title: "Implement and deploy a balorg worker based on scriptworker"
    bug: 1277871
    done: true
    assigned: mtabara

automatic-retry-android-jobs:
    title: "Automatically retry Android jobs with specific kinds of failures"
    assigned: gbrown
    bug: 1280570
    dependencies:
        - docker-worker-retry-on
    done: true

docker-worker-retry-on:
    title: "Support automatically retrying on some failures in docker-worker"
    done: true

nightly-beetmover-tier2:
    title: "beetmover tasks implemented in-tree for tier2 platforms"
    assigned: kmoir
    done: true
    dependencies:
        - beetmover-worker-impl

nightly-single-locale-beetmover-tier2:
    title: "beetmover tasks for single-locale builds"
    description: |
        Implement tasks for beetmover that can handle the additional complexity of
        artifact names containing locale names.
    assigned: kmoir
    done: true
    dependencies:
        - beetmover-worker-impl

stop-bb-linux-test-masters:
    title: "Turn off the Linux Test Buildmasters (except one for ESR et al.)"
    dependencies:
        - linux64-talos-on-hardware-100pct
        # android tests use the linux test masters
        - android-opt-tier1

docker-worker-cot-gpg-keys-in-repo:
    title: "Set up a process for generating and adding keys to the cot gpg repo for every docker-worker deployment (reimage or AMI generation)"
    assigned: garndt
    done: true

separate-tier3-gpg-keys:
    title: separate the gpg keys for tier3 workers from non-tier3
    bug: 1333650

generic-worker-cot-gpg-keys-in-repo:
    title: "Set up a process for generating and adding keys to the cot gpg repo for every generic-worker deployment (reimage or AMI generation)"
    description: |
        The automation that creates AMIs based on OpenCloudConfig commits will create a pull request against the gpg repository with the new key,
        and block deploying the new AMI until that PR is signed and merged.

taskcluster-worker-cot-gpg-keys-in-repo:
    title: "Set up a process for generating and adding keys to the cot gpg repo for every taskcluster-worker deployment (reimage or AMI generation)"
    duration: 3

scriptworker-chain-of-trust-verification:
    title: "Enable chain of trust verification, and block on it before scriptworker jobs"
    assigned: aki
    bug: 1309293
    done: true

beetmover-chain-of-trust:
    title: "Enable chain of trust verification in beetmover scriptworker script"
    bug: 1317747
    duration: 5
    done: true
    assigned: jlund

pushapk-chain-of-trust:
    title: "Enable chain of trust verification in pushapk scriptworker script"
    bug: 1317783

balrog-chain-of-trust:
    title: "Enable chain of trust verification in the balrog scriptworker script"
    bug: 1317800
    done: true
    assigned: mtabara

docker-image-sha-doesnt-match:
    title: "add info for scriptworker to be able to verify built docker image SHA"
    bug:  1315415
    assigned: garndt
    done: true

scriptworker-queue-monitoring:
    title: "Monitor scriptworker queues and alert when too large"
    bug: 1314840
    duration: 5
    assigned: sfraser

scriptworker-nagios:
    title: "Monitor scriptworker instances and alert on issues"
    bug: 1314840
    duration: 5
    assigned: sfraser

scriptworker-iptables:
    title: "Block non-required scriptworker ports/traffic"
    duration: 5
    bug: 1308980

scriptworker-audit-new-instance-types:
    title: "audit the new scriptworker instance types for rra/pentest compliance"

scriptworker-ssh-alerts:
    title: "Alerts on ssh to scriptworker instances"
    bug: 1290261
    assigned: phrozyn

scriptworker-tier1:
    title: "Scriptworker is tier1-ready"
    assigned: aki
    bug: 1317789
    done: true
    dependencies:
        - scriptworker-chain-of-trust-verification
        - beetmover-chain-of-trust
        - balrog-chain-of-trust
        - docker-image-sha-doesnt-match

cot-rebuild-decision-task:
    title: verify chain of trust by rebuilding the decision task
    assigned: aki
    bug: 1328719
    dependencies:
        - cron-tasks
        - in-tree-docker-shas
        - in-tree-mozilla-taskcluster

cron-tasks:
    title: allow for in-tree cron tasks
    assigned: dustin
    bug: 1252948

in-tree-docker-shas:
    title: move decision and docker-image docker image shas in-tree
    bug: 1326436

in-tree-mozilla-taskcluster:
    title: move mozilla-taskcluster tree info in-tree
    bug: 1328727

allow-many-routes:
    title: get around max 4k index routes with a dummy task
    assigned: jonasfj
    bug: 1333255

make-check-ok-for-cross-compile:
    title: "For each make-check check, either split it to a test task, confirm it runs in cross-compilation, or remove"
    assigned: mshal
    bug: 992323
    duration: 15
    description: |
        There are a few tests that check properties of binaries, which should
        run ok in cross-compilation.  Everything else must either be moved to a
        test task (so it can run on the target OS) or removed.
    dependencies:
        - split-python-unit-tests

pulse-actions-backfill:
    title: "Add support for backfilling jobs"
    bug: 1289823
    assigned: bstack
    done: true

pulse-actions-missing-talos:
    title: "Add support for backfilling all talos jobs on a push"
    bug: 1289824
    assigned: bstack

docker-generic-taskcluster-worker-priority-support:
    title: "Use queue.claimWork in {docker,generic,taskcluster}-worker, load test"
    assigned: jonasfj
    duration: 5
    bug: 1331094
    description: |
        Each of these three worker implementations needs to be updated to use
        the `queue.claimWork` operation, followed by a staged deployment to
        ensure that the queue service is not overwhelmed by the load.

script-worker-priority-support:
    title: "Use queue.claimWork in scriptworker"
    duration: 10
    bug: 1331098
    description: |
        Update scriptworker to use the `queue.claimWork` operation.  This will
        be deployed only after the deployment for
        {docker,generic,taskcluster}-worker is complete, to ensure the queue
        service can handle the load.
    dependencies:
        - docker-generic-taskcluster-worker-priority-support

bbb-priority-support:
    title: "Use queue.claimWork in buildbot-bridge"
    duration: 10
    description: |
        Update buildbot-bridge to use the `queue.claimWork` operation.  This will
        be deployed only after the deployment for
        {docker,generic,taskcluster}-worker is complete, to ensure the queue
        service can handle the load.
    bug: 1331096
    dependencies:
        - docker-generic-taskcluster-worker-priority-support

worker-priority-support:
    title: "Support for priorities in TaskCluster workers"
    description: |
        This involves implementing support for the `queue.claimWork` operations
        throughout the queue and workers, then adding new priority levels in queue.
    bug: 1231781
    assigned: jonasfj
    duration: 0
    dependencies:
        - bbb-priority-support
        - script-worker-priority-support
        - docker-generic-taskcluster-worker-priority-support

scriptworker-hg-committer:
    title: "Implement a scriptworker script that can safely land commits to hg"

periodic-tasks:
    title: "Implement in-tree support for periodically executing certain tasks"
    bug: 1252948
    description: |
        Lots of tasks need to run periodically, and those tasks and their
        frequency should be controllable in-tree.  This is the `.cron.yml`
        proposal.  This is useful for tasks outside of the migration, too,
        such as valgrind.

periodic-update-service:
    title: "Implement the periodic update service"
    description: |
        We periodically land automatic updates to HSTS, HPKP, and the
        blocklist.  These will use the hg-committer scriptworker to actually
        land the changes, but also need to run periodically, independent of
        regular pushes.
    bug: 1171193
    dependencies:
        - periodic-tasks
        - scriptworker-tier1
        - scriptworker-hg-committer

generic-worker-terminate-on-ami-update:
    # this is necessary for parity with Buildbot, where we can ship environment changes in <96 hours
    title: "Implement the ability for generic-worker instance to terminate themselves when they are idle and running an old workerType definition"
    bug: 1298010
    assigned: pmoore
    done: true

fuzzing:
    title: "Implement fuzzing in taskcluster (TBD)"

taskcluster-worker-setup-cleanup:
    title: "Add support to Taskcluster-Worker for pre-task setup and post-task cleanup work"
    duration: 20
    description: |
        For Buildbot jobs, runner takes care of some pre-task setup (warming
        caches, for example, to reduce end-to-end time) and post-task cleanup
        (clearing temporary directories, killing stray processes, etc.).  We
        will need similar functionality with taskcluster-worker, either by
        using runner or implementing it with some other mechanism

scriptworker-cancel-tasks:
    title: "Support for cancelling tasks in scriptworker"

taskcluster-worker-cancel-tasks:
    title: "Support for cancelling tasks in taskcluster-worker"
    duration: 10
    bug: 1295686

split-python-unit-tests:
    title: "Move Python unit tests currently run in 'make check' into a separate job"
    assigned: ahal
    bug: 1003417
    description: |
        Run those Python unit tests that do not require an objdir in a separate
        task, so that it can execute in parallel with the other test tasks, and
        so that it can succeed for cross-compiled builds.

nightly-checksum-signing:
    title: "Create a nightly checksum signing task"
    assigned: mtabara
    bug: 1305139
    description: |
        In TC world we don't pass our signing token to the build job. So
        similar to how we sign the apk with signingscript, we should create
        another task in the nightly graph that signs the checksums artifact.

artifact-list-changes:
    title: "Allow for artifact list changes without bustage"
    bug: 1331141
    description: |
        Currently we have an in-tree graph with the simple names to beetmove.  We also have a bunch of yaml manifests in beetmoverscript describing the simple name -> prEtty name conversion. When we add new artifacts to the list, we need to be able to do so in a way that doesn't require simultaneous updates to both sides.  Also, if we have the manifests out-of-tree, at some point the trains' artifact lists will diverge, and beetmoverscript will have to handle all variants.  (esr vs aurora/beta/release vs nightly)

declarative-manifests:
    title: "Create a manifest with artifact names that the build system then uses to name its output files"
    bug: 1331143
    description: |
        We can use a declarative manifest to generate the taskcluster graph, and the build system could use it to know what to name its artifacts.  If the names are pretty names, beetmover doesn't have to perform any name transforms at all, and can just push pretty-named artifacts to the proper s3 bucket.
